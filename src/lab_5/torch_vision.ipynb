{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import lru_cache\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "\n",
    "@lru_cache\n",
    "def _download_data():\n",
    "    data = torchvision.datasets.FashionMNIST(\n",
    "        \"path\", download=True, transform=transforms.ToTensor()\n",
    "    )\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_train_val_loaders(\n",
    "    batch_size: int,\n",
    "    fraction_of_train_set: float = 1.0\n",
    ") -> tuple[DataLoader, DataLoader]:\n",
    "    dataset = _download_data()\n",
    "    train_size = int(fraction_of_train_set * 0.8 * len(dataset))\n",
    "    val_size = len(dataset) - train_size\n",
    "    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    return (train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data presentation tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.axes import Axes\n",
    "\n",
    "\n",
    "def plot_metrics(results: list[dict[str, float]]):\n",
    "    x = [i for i in range(len(results))]\n",
    "    accuracy = [results[i]['accuracy'] for i in x]\n",
    "    recall = [results[i]['recall'] for i in x]\n",
    "    f1 = [results[i]['f1'] for i in x]\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(x, accuracy, linestyle='-', color='b', label='Accuracy')\n",
    "    plt.plot(x, recall, linestyle='-', color='r', label='Recall')\n",
    "    plt.plot(x, f1, linestyle='-', color='g', label='F1 Score')\n",
    "\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Metric score')\n",
    "    plt.title('Plot of metric scores')\n",
    "\n",
    "    plt.xlim(0, len(results))\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_cost(results: list[dict[str, float]]):\n",
    "    x = [i for i in range(len(results))]\n",
    "    cost = [results[i]['cost'] for i in x]\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(x, cost, linestyle='-', color='r', label='Cost')\n",
    "\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Cost function value')\n",
    "    plt.title('Plot of cost value over time (epochs)')\n",
    "\n",
    "    plt.xlim(0, len(results))\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def compare_plots(results_with_titles: list[tuple[dict, str]], cost: bool = False):\n",
    "    count = len(results_with_titles)\n",
    "    # cols = min(count, 3)\n",
    "    # rows = ((count - 1) // 3) + 1\n",
    "    cols = min(count, 2)\n",
    "    rows = ((count - 1) // 2) + 1\n",
    "\n",
    "    fig, axs = plt.subplots(nrows=rows, ncols=cols, figsize=(12, 6))\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            ax: Axes = axs[i][j] if rows > 1 else axs[j]\n",
    "            # if (3 * i) + j < count:\n",
    "            if (2 * i) + j < count:\n",
    "                # res, title = results_with_titles[(3 * i) + j]\n",
    "                res, title = results_with_titles[(2 * i) + j]\n",
    "                x = [k for k in range(len(res))]\n",
    "                if cost:\n",
    "                    cost = [res[j]['cost'] for j in x]\n",
    "                    ax.plot(x, cost, linestyle='-', color='r', label='Cost')\n",
    "                else:\n",
    "                    accuracy = [res[j]['accuracy'] for j in x]\n",
    "                    recall = [res[j]['recall'] for j in x]\n",
    "                    f1 = [res[j]['f1'] for j in x]\n",
    "                    ax.plot(x, accuracy, linestyle='-', color='b', label='Accuracy')\n",
    "                    ax.plot(x, recall, linestyle='-', color='r', label='Recall')\n",
    "                    ax.plot(x, f1, linestyle='-', color='g', label='F1 Score')\n",
    "                    ax.set_ylim(0, 1)\n",
    "                ax.set_title(title)\n",
    "                ax.set_xlim(0, len(res))\n",
    "                ax.legend()\n",
    "                ax.grid(True)\n",
    "            else:\n",
    "                ax.set_visible(False)\n",
    "\n",
    "    fig.supxlabel('Epoch', fontsize=12)\n",
    "    if cost:\n",
    "        fig.supylabel('Cost function value', fontsize=12)\n",
    "        fig.suptitle('Plot of cost value over time (epochs)', fontsize=14)\n",
    "    else:\n",
    "        fig.supylabel('Metric scores', fontsize=12)\n",
    "        fig.suptitle('Plot of metric scores over time (epochs)', fontsize=14)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.9)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Callable\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class HiddenLayerConfig:\n",
    "    neurons: int\n",
    "    f_activ: nn.Module\n",
    "\n",
    "\n",
    "# Define the model\n",
    "class ImageClassifier(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_features: int,\n",
    "        output_labels: int,\n",
    "        hidden_layers_config: list[HiddenLayerConfig]\n",
    "    ):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        for i in range(len(hidden_layers_config)):\n",
    "            input_size = input_features if i == 0 else hidden_layers_config[i-1].neurons\n",
    "            layers.append(nn.Linear(input_size, hidden_layers_config[i].neurons))\n",
    "            layers.append(hidden_layers_config[i].f_activ)\n",
    "        layers.append(nn.Linear(hidden_layers_config[-1].neurons, output_labels))\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        # Init weights\n",
    "        self.layers.apply(self._init_weights)\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "    def _init_weights(self, module: nn.Module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.xavier_uniform_(module.weight)\n",
    "            nn.init.zeros_(module.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, recall_score\n",
    "from torch.nn.modules import Module\n",
    "from torch.optim.optimizer import Optimizer\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "def train_one_epoch(\n",
    "    model: ImageClassifier,\n",
    "    train_loader: DataLoader,\n",
    "    loss_fn: Module,\n",
    "    optimizer: Optimizer\n",
    "):\n",
    "    for X, y in train_loader:\n",
    "        # Zero gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        y_pred = model(X)\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "def train_model(\n",
    "    model: ImageClassifier,\n",
    "    max_epochs: int,\n",
    "    train_loader: DataLoader,\n",
    "    val_loader: DataLoader,\n",
    "    loss_fn: Module,\n",
    "    optimizer: Optimizer,\n",
    "    debug: bool = False\n",
    "):\n",
    "    results = []\n",
    "    prev_avg_val_loss = 0.0\n",
    "    # Initialize training\n",
    "    for epoch in range(max_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "\n",
    "        # Train for one epoch\n",
    "        train_one_epoch(\n",
    "            model=model,\n",
    "            train_loader=train_loader,\n",
    "            loss_fn=loss_fn,\n",
    "            optimizer=optimizer,\n",
    "        )\n",
    "\n",
    "        model.eval()\n",
    "        running_val_loss = 0.0\n",
    "        all_labels = []\n",
    "        all_preds = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for X, y in val_loader:\n",
    "                y_pred = model(X)\n",
    "                val_loss = loss_fn(y_pred, y)\n",
    "                running_val_loss += val_loss.item()\n",
    "\n",
    "                predicted_classes = torch.argmax(y_pred, dim=1)\n",
    "                all_labels.extend(y.cpu().numpy())\n",
    "                all_preds.extend(predicted_classes.cpu().numpy())\n",
    "\n",
    "        # Calculate metrics for the epoch\n",
    "        accuracy = accuracy_score(all_labels, all_preds)\n",
    "        recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "        f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "        avg_val_loss = running_val_loss / len(val_loader)\n",
    "\n",
    "        results.append({\n",
    "            \"accuracy\": accuracy,\n",
    "            \"recall\": recall,\n",
    "            \"f1\": f1,\n",
    "            \"cost\": avg_val_loss\n",
    "        })\n",
    "\n",
    "        delta = avg_val_loss - prev_avg_val_loss\n",
    "        if debug:\n",
    "            print(f\"Epoch [{epoch+1}/{max_epochs}] - avg val loss: {avg_val_loss:.4f} (delta: {delta})\")\n",
    "        prev_avg_val_loss = avg_val_loss\n",
    "\n",
    "    print(\"Training complete!\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multiclass and continuous-multioutput targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 19\u001b[0m\n\u001b[0;32m      8\u001b[0m model \u001b[38;5;241m=\u001b[39m ImageClassifier(\n\u001b[0;32m      9\u001b[0m     input_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m28\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m28\u001b[39m,  \u001b[38;5;66;03m# For FashionMNIST images,\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     output_labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,  \u001b[38;5;66;03m# For FashionMNIST images,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m     ]\n\u001b[0;32m     15\u001b[0m )\n\u001b[0;32m     17\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mSGD(model\u001b[38;5;241m.\u001b[39mparameters())\n\u001b[1;32m---> 19\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCrossEntropyLoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# tb_writer: SummaryWriter = None\u001b[39;49;00m\n\u001b[0;32m     27\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m plot_metrics(results)\n\u001b[0;32m     30\u001b[0m plot_cost(results)\n",
      "Cell \u001b[1;32mIn[16], line 67\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, max_epochs, train_loader, val_loader, loss_fn, optimizer, debug)\u001b[0m\n\u001b[0;32m     64\u001b[0m         all_preds\u001b[38;5;241m.\u001b[39mextend(y_pred\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# Calculate metrics for the epoch\u001b[39;00m\n\u001b[1;32m---> 67\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m \u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_preds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m recall \u001b[38;5;241m=\u001b[39m recall_score(all_labels, all_preds, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweighted\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     69\u001b[0m f1 \u001b[38;5;241m=\u001b[39m f1_score(all_labels, all_preds, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweighted\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Kris\\Documents\\Studia\\Semestr_VII\\sieci_neuronowe\\laboratorium\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Kris\\Documents\\Studia\\Semestr_VII\\sieci_neuronowe\\laboratorium\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:231\u001b[0m, in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    229\u001b[0m xp, _, device \u001b[38;5;241m=\u001b[39m get_namespace_and_device(y_true, y_pred, sample_weight)\n\u001b[0;32m    230\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[1;32m--> 231\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\Kris\\Documents\\Studia\\Semestr_VII\\sieci_neuronowe\\laboratorium\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:112\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m    109\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 112\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    113\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    114\u001b[0m             type_true, type_pred\n\u001b[0;32m    115\u001b[0m         )\n\u001b[0;32m    116\u001b[0m     )\n\u001b[0;32m    118\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[0;32m    119\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and continuous-multioutput targets"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "BATCH_SIZE = 30\n",
    "\n",
    "train_loader, val_loader = get_train_val_loaders(batch_size=16)\n",
    "train_loader.batch_sampler\n",
    "\n",
    "model = ImageClassifier(\n",
    "    input_features=28 * 28,  # For FashionMNIST images,\n",
    "    output_labels=10,  # For FashionMNIST images,\n",
    "    hidden_layers_config=[\n",
    "        HiddenLayerConfig(14, nn.Sigmoid()),\n",
    "        HiddenLayerConfig(7, nn.Sigmoid())\n",
    "    ]\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters())\n",
    "\n",
    "results = train_model(\n",
    "    model=model,\n",
    "    max_epochs=1,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    loss_fn=nn.CrossEntropyLoss(),\n",
    "    optimizer=optimizer,\n",
    "    # tb_writer: SummaryWriter = None\n",
    ")\n",
    "\n",
    "plot_metrics(results)\n",
    "plot_cost(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
